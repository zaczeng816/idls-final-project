{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeb05ce02724cc0bcf2567712f04bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/337 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb561955bfa4021961338b98b5744e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87b6883f9f2450d9ef1264ba1052f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83c7acac8bc41738f298c36758ba663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/17 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22ecc116af341cd8e71fec3a67a2127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00017.parquet:   0%|          | 0.00/211M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65901d6d5d1a4062817919f81f2dfa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00017.parquet:   0%|          | 0.00/211M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0882bab29949689601cc92acdb1ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00017.parquet:   0%|          | 0.00/211M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b363976702714d8db85fb03239a2b594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00017.parquet:   0%|          | 0.00/211M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91aa6e14d274ca7a726d9f18aca9963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00017.parquet:   0%|          | 0.00/194M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b081a95541214d1898c71fa748cb7ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00017.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d706aa95c6c6457bbae8bade9e730148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00017.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b146b22e93724db59a566a9388709936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00017.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2411ed4b64de4da2b17778fd15e9d64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00017.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ab903ffdc44fe9b1534c229f73ec8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00009-of-00017.parquet:   0%|          | 0.00/254M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a7d4692432404199968bbfb2e18a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00010-of-00017.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199058cab2824f67b2f55ca64ef69163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00011-of-00017.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fbe86417ce46dab0c3bc277f35cb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00012-of-00017.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71cafdba53f4987ad268e1d5e387344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00013-of-00017.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaeab1a3b28b4983ab2175c5b85a2342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00014-of-00017.parquet:   0%|          | 0.00/200M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6776c96327a64ab68dfa45d0e7241b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00015-of-00017.parquet:   0%|          | 0.00/326M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865e81af4be34d3ba73d7a8ea3e06b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00016-of-00017.parquet:   0%|          | 0.00/326M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edfe738acbd4720942e6f306fc50397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11846109 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5a25f666cf472384de54a270b4cb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"TinyGSM/TinyGSM\", cache_dir=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7622ccbaeb4db1901ba84a510864f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865aac466c6046adb63e46e84d009837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a622655545024fa397c065e4b2d58fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8413207f348a42708d47527f2b3cc4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69bbe002fca4107beb192d75e237805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0790a600f24ad78d96d3175a8710b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42127db69b03465a9ae90348f2f8376a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5dc009c9b847d192f84dd22fae113a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abb4e0da66247c9b2db2f3b3aeff75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2025899aa4264b9d8223151f67661534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4dbebaaa324d8095468b9a26d90400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain quantum computing in simple terms: what is it, and why is it important?\n",
      "\n",
      "What is the role of the nurse in clinical documentation?\n",
      "\n",
      "A 1.00-mol sample of an ideal monatomic gas, originally at a pressure of $1.00 \\mathrm{~atm}$, undergoes a three-step process: (1) it is expanded adiabatically from $T_1=588 \\mathrm{~K}$ to $T_2=389 \\mathrm{~K}:$ (2) it is compressed at constant pressure until its temperature reaches $T_3 ;(3)$ it then returns to its original pressure and temperature by a constant-volume process. Plot these processes on a $P V$ diagram.\n",
      "\n",
      "Explain why the melting point is the lowest of any known substance at $-78{ }^{\\circ} \\mathrm{C}$.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/gemma-2b\"  # or \"google/gemma-7b\" for the larger model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Explain quantum computing in simple terms:\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gemma(messages):\n",
    "    # Format messages in chat format\n",
    "    formatted_prompt = \"\"\n",
    "    for msg in messages:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            formatted_prompt += f\"<start_of_turn>user\\n{msg['content']}<end_of_turn>\\n\"\n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            formatted_prompt += f\"<start_of_turn>assistant\\n{msg['content']}<end_of_turn>\\n\"\n",
    "    \n",
    "    formatted_prompt += \"<start_of_turn>assistant\\n\"\n",
    "    \n",
    "    response = generate_response(formatted_prompt)\n",
    "    return response\n",
    "\n",
    "# Example chat\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is machine learning?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Machine learning is a type of artificial intelligence...\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you give me an example?\"}\n",
    "]\n",
    "\n",
    "response = chat_with_gemma(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
